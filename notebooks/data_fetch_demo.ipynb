{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fetch Demo\n",
    "\n",
    "This notebook demonstrates the data fetching functionality for collecting CTA transit-related posts and comments from Reddit and Bluesky.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The data fetch module (`cta_pipeline/data_fetch.py`) provides shared utilities:\n",
    "- **RateLimiter**: Sliding window rate limiting for API calls\n",
    "- **RetryConfig / with_retry**: Retry logic with exponential backoff\n",
    "- **Anonymizer**: Consistent anonymization of user data while preserving relationships\n",
    "- **Filter lists**: Blocked users, news accounts, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from cta_pipeline.data_fetch import (\n",
    "    Anonymizer,\n",
    "    RateLimiter,\n",
    "    RetryConfig,\n",
    "    with_retry,\n",
    "    fetch_json,\n",
    "    is_blocked_user,\n",
    "    contains_blocked_keywords,\n",
    "    REDDIT_HEADERS,\n",
    ")\n",
    "from cta_pipeline.constants import REDDIT_SUBREDDITS, BLUESKY_QUERIES\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Anonymizer Demo\n",
    "\n",
    "The Anonymizer generates consistent anonymous IDs while preserving relationships between posts and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== User Anonymization ===\n",
      "  john_doe             -> user_58d20899d485\n",
      "  jane_smith           -> user_28b45eefca23\n",
      "  john_doe             -> user_58d20899d485\n",
      "  transit_lover        -> user_11b228375d03\n",
      "\n",
      "=== Post ID Anonymization ===\n",
      "  abc123               -> post_c395eef34d82\n",
      "  def456               -> post_f50c6d85e137\n",
      "  abc123               -> post_c395eef34d82\n",
      "\n",
      "=== Relationship Preservation ===\n",
      "Notice that 'john_doe' and 'abc123' produce the same hash each time.\n",
      "This is done to preserve comment --> post and reply --> parent relationships while maintaining privacy.\n"
     ]
    }
   ],
   "source": [
    "# Create an anonymizer instance\n",
    "anonymizer = Anonymizer()\n",
    "\n",
    "# Sample data\n",
    "sample_users = [\"john_doe\", \"jane_smith\", \"john_doe\", \"transit_lover\"]\n",
    "sample_post_ids = [\"abc123\", \"def456\", \"abc123\"]\n",
    "\n",
    "print(\"=== User Anonymization ===\")\n",
    "for user in sample_users:\n",
    "    anon = anonymizer.anonymize_author(user)\n",
    "    print(f\"  {user:20} -> {anon}\")\n",
    "\n",
    "print(\"\\n=== Post ID Anonymization ===\")\n",
    "for post_id in sample_post_ids:\n",
    "    anon = anonymizer.anonymize_post_id(post_id)\n",
    "    print(f\"  {post_id:20} -> {anon}\")\n",
    "\n",
    "print(\"\\n=== Relationship Preservation ===\")\n",
    "print(\"Notice that 'john_doe' and 'abc123' produce the same hash each time.\")\n",
    "print(\"This is done to preserve comment --> post and reply --> parent relationships while maintaining privacy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter Functions Demo\n",
    "\n",
    "The filter functions help exclude bots, news accounts, and non-CTA transit (Metra, AMTRAK, etc) content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Blocked User Detection ===\n",
      "  AutoModerator                  (reddit  ) -> BLOCKED\n",
      "  regular_user                   (reddit  ) -> allowed\n",
      "  chicagotribune.com             (bluesky ) -> BLOCKED\n",
      "  transit_fan.bsky.social        (bluesky ) -> allowed\n",
      "\n",
      "=== Blocked Keywords Detection ===\n",
      "  \"The CTA Red Line was delayed today...\" -> allowed (CTA-related)\n",
      "  \"Taking Metra to work is great...\" -> BLOCKED (non-CTA)\n",
      "  \"Amtrak prices are too high...\" -> BLOCKED (non-CTA)\n",
      "  \"Love the Blue Line express...\" -> allowed (CTA-related)\n"
     ]
    }
   ],
   "source": [
    "# Test blocked user detection\n",
    "print(\"=== Blocked User Detection ===\")\n",
    "test_users = [\n",
    "    (\"AutoModerator\", \"reddit\"),\n",
    "    (\"regular_user\", \"reddit\"),\n",
    "    (\"chicagotribune.com\", \"bluesky\"),\n",
    "    (\"transit_fan.bsky.social\", \"bluesky\"),\n",
    "]\n",
    "\n",
    "for user, platform in test_users:\n",
    "    blocked = is_blocked_user(user, platform)\n",
    "    status = \"BLOCKED\" if blocked else \"allowed\"\n",
    "    print(f\"  {user:30} ({platform:8}) -> {status}\")\n",
    "\n",
    "print(\"\\n=== Blocked Keywords Detection ===\")\n",
    "test_texts = [\n",
    "    \"The CTA Red Line was delayed today\",\n",
    "    \"Taking Metra to work is great\",\n",
    "    \"Amtrak prices are too high\",\n",
    "    \"Love the Blue Line express\",\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    blocked = contains_blocked_keywords(text)\n",
    "    status = \"BLOCKED (non-CTA)\" if blocked else \"allowed (CTA-related)\"\n",
    "    print(f\"  \\\"{text[:40]}...\\\" -> {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rate Limiter Demo\n",
    "\n",
    "The RateLimiter component ensures we don't exceed API rate limits. It can be configured for different social media services as per their specified API rate limits. In the final scripts, we try to aim slightly lower than the rate limits, just to be safe with our requests and avoiding failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Rate Limiter Demo ===\n",
      "Configured: 5 calls per 10 seconds\n",
      "\n",
      "Simulating API calls...\n",
      "  Call 1 completed at 08:48:32\n",
      "  Call 2 completed at 08:48:32\n",
      "  Call 3 completed at 08:48:32\n",
      "  Call 4 completed at 08:48:32\n",
      "  Call 5 completed at 08:48:32\n",
      "{\"sleep_seconds\": 10.0, \"calls_made\": 5, \"event\": \"rate_limit_sleep\", \"level\": \"info\", \"timestamp\": \"2025-12-22T13:48:32.893910Z\", \"func_name\": \"check\", \"filename\": \"data_fetch.py\", \"lineno\": 45}\n",
      "  Call 6 completed at 08:48:42\n",
      "\n",
      "Note: In production, limits are 2800/5min for Bluesky, 30/min for Reddit\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Create a rate limiter (5 calls per 10 seconds for demo)\n",
    "rate_limiter = RateLimiter(max_calls=5, window_seconds=10)\n",
    "\n",
    "print(\"=== Rate Limiter Demo ===\")\n",
    "print(f\"Configured: {rate_limiter.max_calls} calls per {rate_limiter.window_seconds} seconds\")\n",
    "print(\"\\nSimulating API calls...\")\n",
    "\n",
    "for i in range(6):\n",
    "    rate_limiter.check()  # Will sleep if at limit\n",
    "    rate_limiter.increment()\n",
    "    print(f\"  Call {i+1} completed at {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nNote: In production, limits are 2800/5min for Bluesky, 30/min for Reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reddit Data Fetch Sample\n",
    "\n",
    "Let's fetch a small sample of posts from one subreddit to demonstrate the functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Configured Subreddits ===\n",
      "  r/Chicago\n",
      "  r/AskChicago\n",
      "  r/CarFreeChicago\n",
      "  r/AskCHI\n",
      "  r/cta\n",
      "  r/ChicagoUrbanism\n",
      "  r/WindyCity\n",
      "  r/ChicagoNWSide\n",
      "  r/greatNWSide\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Configured Subreddits ===\")\n",
    "for sub in REDDIT_SUBREDDITS:\n",
    "    print(f\"  r/{sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fetching Sample Posts from r/cta ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cta</td>\n",
       "      <td>Full sized CTA map...</td>\n",
       "      <td>Previous_Mastodon212</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cta</td>\n",
       "      <td>Does the Santa car have an assigned number?...</td>\n",
       "      <td>HinsdaleCounty</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cta</td>\n",
       "      <td>CPD On Cta...</td>\n",
       "      <td>Queasy-History4464</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cta</td>\n",
       "      <td>Red Line Seats...</td>\n",
       "      <td>avec_n</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cta</td>\n",
       "      <td>Most CTA drivers are assholes and it gets wors...</td>\n",
       "      <td>Pristine-Angle3100</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  \\\n",
       "0       cta                              Full sized CTA map...   \n",
       "1       cta     Does the Santa car have an assigned number?...   \n",
       "2       cta                                      CPD On Cta...   \n",
       "3       cta                                  Red Line Seats...   \n",
       "4       cta  Most CTA drivers are assholes and it gets wors...   \n",
       "\n",
       "                 author  score  num_comments  \n",
       "0  Previous_Mastodon212      9             6  \n",
       "1        HinsdaleCounty      9             5  \n",
       "2    Queasy-History4464      7             6  \n",
       "3                avec_n      3             6  \n",
       "4    Pristine-Angle3100      0             4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetch_sample_reddit_posts(subreddit: str, limit: int = 5):\n",
    "    \"\"\"Fetch a small sample of posts from a subreddit.\"\"\"\n",
    "    url = f\"https://www.reddit.com/r/{subreddit}/search.json\"\n",
    "    params = {\n",
    "        \"q\": \"cta OR train OR bus\",\n",
    "        \"restrict_sr\": 1,\n",
    "        \"limit\": limit,\n",
    "        \"sort\": \"new\",\n",
    "    }\n",
    "    \n",
    "    data = fetch_json(url, params=params, headers=REDDIT_HEADERS)\n",
    "    \n",
    "    if data is None:\n",
    "        print(f\"Failed to fetch from r/{subreddit}\")\n",
    "        return []\n",
    "    \n",
    "    posts = []\n",
    "    for child in data.get(\"data\", {}).get(\"children\", []):\n",
    "        if child.get(\"kind\") != \"t3\":\n",
    "            continue\n",
    "        post_data = child.get(\"data\", {})\n",
    "        posts.append({\n",
    "            \"subreddit\": subreddit,\n",
    "            \"title\": post_data.get(\"title\", \"\")[:60] + \"...\",\n",
    "            \"author\": post_data.get(\"author\", \"\"),\n",
    "            \"score\": post_data.get(\"score\", 0),\n",
    "            \"num_comments\": post_data.get(\"num_comments\", 0),\n",
    "        })\n",
    "    \n",
    "    return posts\n",
    "\n",
    "# Fetch sample from r/cta\n",
    "print(\"=== Fetching Sample Posts from r/cta ===\")\n",
    "sample_posts = fetch_sample_reddit_posts(\"cta\", limit=5)\n",
    "\n",
    "if sample_posts:\n",
    "    df = pd.DataFrame(sample_posts)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No posts fetched (rate limited or network issue)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Anonymized Version ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cta</td>\n",
       "      <td>Full sized CTA map...</td>\n",
       "      <td>user_482ebcbbfc2b</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cta</td>\n",
       "      <td>Does the Santa car have an assigned number?...</td>\n",
       "      <td>user_367ac42061f7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cta</td>\n",
       "      <td>CPD On Cta...</td>\n",
       "      <td>user_19146637be4d</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cta</td>\n",
       "      <td>Red Line Seats...</td>\n",
       "      <td>user_00db62e69e47</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cta</td>\n",
       "      <td>Most CTA drivers are assholes and it gets wors...</td>\n",
       "      <td>user_c414a18ad943</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title  \\\n",
       "0       cta                              Full sized CTA map...   \n",
       "1       cta     Does the Santa car have an assigned number?...   \n",
       "2       cta                                      CPD On Cta...   \n",
       "3       cta                                  Red Line Seats...   \n",
       "4       cta  Most CTA drivers are assholes and it gets wors...   \n",
       "\n",
       "              author  score  num_comments  \n",
       "0  user_482ebcbbfc2b      9             6  \n",
       "1  user_367ac42061f7      9             5  \n",
       "2  user_19146637be4d      7             6  \n",
       "3  user_00db62e69e47      3             6  \n",
       "4  user_c414a18ad943      0             4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: Author names are now anonymized but consistent (same author = same hash)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate anonymization of the fetched posts\n",
    "if sample_posts:\n",
    "    print(\"=== Anonymized Version ===\")\n",
    "    anonymizer = Anonymizer()\n",
    "    \n",
    "    anon_posts = []\n",
    "    for post in sample_posts:\n",
    "        anon_posts.append({\n",
    "            \"subreddit\": post[\"subreddit\"],\n",
    "            \"title\": post[\"title\"],\n",
    "            \"author\": anonymizer.anonymize_author(post[\"author\"]),\n",
    "            \"score\": post[\"score\"],\n",
    "            \"num_comments\": post[\"num_comments\"],\n",
    "        })\n",
    "    \n",
    "    df_anon = pd.DataFrame(anon_posts)\n",
    "    display(df_anon)\n",
    "    \n",
    "    print(\"\\nNote: Author names are now anonymized but consistent (same author = same hash)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bluesky Configuration\n",
    "\n",
    "Bluesky requires authentication. Set these environment variables before running the full fetch:\n",
    "\n",
    "```bash\n",
    "export BSKY_USERNAME=your-username.bsky.social\n",
    "export BSKY_PASSWORD=your-app-password\n",
    "```\n",
    "\n",
    "Or create a `.env` file (copy from `.env.example`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bluesky Configuration ===\n",
      "Search queries configured: 6\n",
      "  - cta AND train\n",
      "  - cta AND bus\n",
      "  - cta AND line\n",
      "  - chicago AND train\n",
      "  - chicago AND bus\n",
      "  - chicago AND line\n",
      "\n",
      "=== Environment Variables ===\n",
      "  BSKY_USERNAME: acoffeerunner.bsky.social\n",
      "  BSKY_PASSWORD: ********\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"=== Bluesky Configuration ===\")\n",
    "print(f\"Search queries configured: {len(BLUESKY_QUERIES)}\")\n",
    "for query in BLUESKY_QUERIES:\n",
    "    print(f\"  - {query}\")\n",
    "\n",
    "print(\"\\n=== Environment Variables ===\")\n",
    "username = os.environ.get(\"BSKY_USERNAME\")\n",
    "password = os.environ.get(\"BSKY_PASSWORD\")\n",
    "\n",
    "if username:\n",
    "    print(f\"  BSKY_USERNAME: {username}\")\n",
    "    print(f\"  BSKY_PASSWORD: {'*' * 8 if password else 'NOT SET'}\")\n",
    "else:\n",
    "    print(\"  BSKY_USERNAME: NOT SET\")\n",
    "    print(\"  BSKY_PASSWORD: NOT SET\")\n",
    "    print(\"\\n  To configure, run:\")\n",
    "    print(\"    export BSKY_USERNAME=your-username.bsky.social\")\n",
    "    print(\"    export BSKY_PASSWORD=your-app-password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Bluesky Connection ===\n",
      "  Successfully authenticated as: acoffeerunner.bsky.social\n",
      "\n",
      "=== Fetching Sample Bluesky Posts ===\n",
      "  Author: user_0288c7a08a23\n",
      "  Text: \"Chicago police have been more visible on the CTA Downtown i...\n",
      "\n",
      "  Author: user_0576e6c7bd53\n",
      "  Text: TWU president John Samuelsen is being very disingenuous. MBT...\n",
      "\n",
      "  Author: user_27ff040a7f82\n",
      "  Text: A 52-year-old man was arrested and charged after he set hims...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Bluesky connection if credentials are available\n",
    "if username and password:\n",
    "    try:\n",
    "        from atproto import Client\n",
    "        \n",
    "        print(\"=== Testing Bluesky Connection ===\")\n",
    "        client = Client()\n",
    "        client.login(username, password)\n",
    "        print(f\"  Successfully authenticated as: {username}\")\n",
    "        \n",
    "        # Fetch a small sample\n",
    "        print(\"\\n=== Fetching Sample Bluesky Posts ===\")\n",
    "        results = client.app.bsky.feed.search_posts(\n",
    "            params={\"q\": \"cta AND train\", \"limit\": 3}\n",
    "        )\n",
    "        \n",
    "        anonymizer = Anonymizer()\n",
    "        for post in results.posts[:3]:\n",
    "            text = getattr(post.record, \"text\", \"\")[:60]\n",
    "            author = anonymizer.anonymize_author(post.author.handle)\n",
    "            print(f\"  Author: {author}\")\n",
    "            print(f\"  Text: {text}...\")\n",
    "            print()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "else:\n",
    "    print(\"Skipping Bluesky test (credentials not configured)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running Full Data Fetch\n",
    "\n",
    "To run the full data fetch scripts:\n",
    "\n",
    "### Reddit\n",
    "```bash\n",
    "python reddit_data_fetch.py\n",
    "```\n",
    "\n",
    "Output files:\n",
    "- `data/posts/reddit/reddit_posts.csv`\n",
    "- `data/posts/reddit/reddit_comments.csv`\n",
    "\n",
    "### Bluesky\n",
    "```bash\n",
    "# Set credentials first\n",
    "export BSKY_USERNAME=your-username.bsky.social\n",
    "export BSKY_PASSWORD=your-app-password\n",
    "\n",
    "python bsky_data_fetch.py\n",
    "```\n",
    "\n",
    "Output files:\n",
    "- `data/posts/bsky/bsky_posts.csv`\n",
    "- `data/posts/bsky/bsky_comments.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Existing Data Files ===\n",
      "  data/posts/reddit/reddit_posts.csv: 876.6 KB\n",
      "    Columns: ['post_id', 'subreddit', 'index', 'timestamp', 'text', 'num_comments', 'permalink']\n",
      "    Sample rows: 3\n",
      "  data/posts/reddit/reddit_comments.csv: 8733.6 KB\n",
      "    Columns: ['post_id', 'comment_id', 'parent_id', 'timestamp', 'body', 'author', 'score', 'is_post']\n",
      "    Sample rows: 3\n",
      "  data/posts/bsky/bsky_posts.csv: 4285.7 KB\n",
      "    Columns: ['post_id', 'parent_id', 'author', 'text', 'timestamp']\n",
      "    Sample rows: 3\n",
      "  data/posts/bsky/bsky_comments.csv: 10850.4 KB\n",
      "    Columns: ['post_id', 'comment_id', 'parent_comment_id', 'author', 'text', 'timestamp']\n",
      "    Sample rows: 3\n"
     ]
    }
   ],
   "source": [
    "# Check if output files already exist\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=== Existing Data Files ===\")\n",
    "\n",
    "data_files = [\n",
    "    \"data/posts/reddit/reddit_posts.csv\",\n",
    "    \"data/posts/reddit/reddit_comments.csv\",\n",
    "    \"data/posts/bsky/bsky_posts.csv\",\n",
    "    \"data/posts/bsky/bsky_comments.csv\",\n",
    "]\n",
    "\n",
    "for file_path in data_files:\n",
    "    path = Path(\"..\") / file_path\n",
    "    if path.exists():\n",
    "        size = path.stat().st_size / 1024\n",
    "        print(f\"  {file_path}: {size:.1f} KB\")\n",
    "        \n",
    "        # Show sample if CSV\n",
    "        if path.suffix == \".csv\":\n",
    "            try:\n",
    "                df = pd.read_csv(path, nrows=3)\n",
    "                print(f\"    Columns: {list(df.columns)}\")\n",
    "                print(f\"    Sample rows: {len(df)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Error reading: {e}\")\n",
    "    else:\n",
    "        print(f\"  {file_path}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating a Combined Sample Dataset\n",
    "\n",
    "Let's create a sample dataset of 2000 comments combining both Reddit and Bluesky data. This demonstrates how to merge data from multiple sources for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 33,020 Reddit comments\n",
      "Loaded 29,801 Bluesky comments\n",
      "\n",
      "Total combined: 62,821 comments\n",
      "\n",
      "Source distribution:\n",
      "  reddit: 33,020 (52.6%)\n",
      "  bluesky: 29,801 (47.4%)\n",
      "\n",
      "Anonymizing user and post data:\n",
      "Anonymized 1,999 rows\n",
      "\n",
      "Sample dataset created\n",
      "Total samples: 1,999\n",
      "\n",
      "Sample source distribution:\n",
      "  reddit: 1,051 (52.6%)\n",
      "  bluesky: 948 (47.4%)\n",
      "\n",
      "Saved to: ../data/sample_comments_2000.csv\n",
      "\n",
      "Sample preview (anonymized):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post_e110fbc897b2</td>\n",
       "      <td>comment_ac38807efd27</td>\n",
       "      <td>user_39467c09ce27</td>\n",
       "      <td>MODS!!!!!</td>\n",
       "      <td>1763339511.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post_0b2e57dfc198</td>\n",
       "      <td>comment_6a6d00e38b6c</td>\n",
       "      <td>user_ad6530f147f1</td>\n",
       "      <td>Looked myself. Couldn't find anything on what ...</td>\n",
       "      <td>1709238607.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post_3e01a205280c</td>\n",
       "      <td>comment_4f820fa3b794</td>\n",
       "      <td>user_753b0bb42975</td>\n",
       "      <td>Among other things that piece of shit in n.v t...</td>\n",
       "      <td>1759987350.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post_a341235980e8</td>\n",
       "      <td>comment_3806052aef0c</td>\n",
       "      <td>user_8fc27ae13848</td>\n",
       "      <td>happy birthday!</td>\n",
       "      <td>1761585157.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post_f66d41d3711f</td>\n",
       "      <td>comment_b2e0aa3929fb</td>\n",
       "      <td>user_34f2c9cb63cb</td>\n",
       "      <td>ICE have been ignoring many laws.\\nIt would be...</td>\n",
       "      <td>2025-08-31T19:12:39.395Z</td>\n",
       "      <td>bluesky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>post_8284caaa558d</td>\n",
       "      <td>comment_3bac8c0bab36</td>\n",
       "      <td>user_caeba23aadfe</td>\n",
       "      <td>www.youtube.com/playlist?lis...\\n\\nI wish like...</td>\n",
       "      <td>2025-12-07T13:51:41.661Z</td>\n",
       "      <td>bluesky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>post_a8a81d6a7a2c</td>\n",
       "      <td>comment_4d2b82efd2e6</td>\n",
       "      <td>user_4ec2a4e8ee1d</td>\n",
       "      <td>\\nEveryone needs to vent sometimes. Here's a f...</td>\n",
       "      <td>1763003021.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>post_fb760a1e5285</td>\n",
       "      <td>comment_4e2c249e4ac8</td>\n",
       "      <td>user_5c59e53795b1</td>\n",
       "      <td>now the very entertaining stuff! budget direct...</td>\n",
       "      <td>2025-09-18T22:55:58.305Z</td>\n",
       "      <td>bluesky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>post_d359c67403aa</td>\n",
       "      <td>comment_3e26878b1aa6</td>\n",
       "      <td>user_a589b1e1f9da</td>\n",
       "      <td>Hotels dot com. Search Soldier Field and filte...</td>\n",
       "      <td>1759443308.0</td>\n",
       "      <td>reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>post_f445c85aae96</td>\n",
       "      <td>comment_1ff3be1c6464</td>\n",
       "      <td>user_82c3d53ddba9</td>\n",
       "      <td>The Second Tunnel is absolutely Essential the ...</td>\n",
       "      <td>2025-07-15T08:37:52.703Z</td>\n",
       "      <td>bluesky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             post_id            comment_id             author  \\\n",
       "0  post_e110fbc897b2  comment_ac38807efd27  user_39467c09ce27   \n",
       "1  post_0b2e57dfc198  comment_6a6d00e38b6c  user_ad6530f147f1   \n",
       "2  post_3e01a205280c  comment_4f820fa3b794  user_753b0bb42975   \n",
       "3  post_a341235980e8  comment_3806052aef0c  user_8fc27ae13848   \n",
       "4  post_f66d41d3711f  comment_b2e0aa3929fb  user_34f2c9cb63cb   \n",
       "5  post_8284caaa558d  comment_3bac8c0bab36  user_caeba23aadfe   \n",
       "6  post_a8a81d6a7a2c  comment_4d2b82efd2e6  user_4ec2a4e8ee1d   \n",
       "7  post_fb760a1e5285  comment_4e2c249e4ac8  user_5c59e53795b1   \n",
       "8  post_d359c67403aa  comment_3e26878b1aa6  user_a589b1e1f9da   \n",
       "9  post_f445c85aae96  comment_1ff3be1c6464  user_82c3d53ddba9   \n",
       "\n",
       "                                                text  \\\n",
       "0                                          MODS!!!!!   \n",
       "1  Looked myself. Couldn't find anything on what ...   \n",
       "2  Among other things that piece of shit in n.v t...   \n",
       "3                                    happy birthday!   \n",
       "4  ICE have been ignoring many laws.\\nIt would be...   \n",
       "5  www.youtube.com/playlist?lis...\\n\\nI wish like...   \n",
       "6  \\nEveryone needs to vent sometimes. Here's a f...   \n",
       "7  now the very entertaining stuff! budget direct...   \n",
       "8  Hotels dot com. Search Soldier Field and filte...   \n",
       "9  The Second Tunnel is absolutely Essential the ...   \n",
       "\n",
       "                  timestamp   source  \n",
       "0              1763339511.0   reddit  \n",
       "1              1709238607.0   reddit  \n",
       "2              1759987350.0   reddit  \n",
       "3              1761585157.0   reddit  \n",
       "4  2025-08-31T19:12:39.395Z  bluesky  \n",
       "5  2025-12-07T13:51:41.661Z  bluesky  \n",
       "6              1763003021.0   reddit  \n",
       "7  2025-09-18T22:55:58.305Z  bluesky  \n",
       "8              1759443308.0   reddit  \n",
       "9  2025-07-15T08:37:52.703Z  bluesky  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "SAMPLE_SIZE = 2000\n",
    "\n",
    "# Load comments from both sources\n",
    "reddit_path = Path(\"..\") / \"data/posts/reddit/reddit_comments.csv\"\n",
    "bsky_path = Path(\"..\") / \"data/posts/bsky/bsky_comments.csv\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Load Reddit comments\n",
    "if reddit_path.exists():\n",
    "    reddit_df = pd.read_csv(reddit_path)\n",
    "    # Normalize columns to common schema\n",
    "    reddit_df = reddit_df.rename(columns={\"body\": \"text\"})\n",
    "    reddit_df[\"source\"] = \"reddit\"\n",
    "    # Select common columns\n",
    "    reddit_df = reddit_df[[\"post_id\", \"comment_id\", \"author\", \"text\", \"timestamp\", \"source\"]]\n",
    "    dfs.append(reddit_df)\n",
    "    print(f\"Loaded {len(reddit_df):,} Reddit comments\")\n",
    "else:\n",
    "    print(\"Reddit comments file not found\")\n",
    "\n",
    "# Load Bluesky comments\n",
    "if bsky_path.exists():\n",
    "    bsky_df = pd.read_csv(bsky_path)\n",
    "    bsky_df[\"source\"] = \"bluesky\"\n",
    "    # Select common columns\n",
    "    bsky_df = bsky_df[[\"post_id\", \"comment_id\", \"author\", \"text\", \"timestamp\", \"source\"]]\n",
    "    dfs.append(bsky_df)\n",
    "    print(f\"Loaded {len(bsky_df):,} Bluesky comments\")\n",
    "else:\n",
    "    print(\"Bluesky comments file not found\")\n",
    "\n",
    "if dfs:\n",
    "    # Combine all sources\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"\\nTotal combined: {len(combined):,} comments\")\n",
    "    \n",
    "    # Sample proportionally from each source\n",
    "    source_counts = combined[\"source\"].value_counts()\n",
    "    print(f\"\\nSource distribution:\")\n",
    "    for source, count in source_counts.items():\n",
    "        pct = count / len(combined) * 100\n",
    "        print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Stratified sampling to maintain source proportions\n",
    "    sample_dfs = []\n",
    "    for source in combined[\"source\"].unique():\n",
    "        source_df = combined[combined[\"source\"] == source]\n",
    "        # Calculate proportional sample size\n",
    "        proportion = len(source_df) / len(combined)\n",
    "        n_samples = int(SAMPLE_SIZE * proportion)\n",
    "        # Sample (or take all if fewer than n_samples)\n",
    "        n_samples = min(n_samples, len(source_df))\n",
    "        sampled = source_df.sample(n=n_samples, random_state=42)\n",
    "        sample_dfs.append(sampled)\n",
    "    \n",
    "    sample_df = pd.concat(sample_dfs, ignore_index=True)\n",
    "    \n",
    "    # Shuffle the combined sample\n",
    "    sample_df = sample_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Anonymize author, post_id, and comment_id\n",
    "    print(\"\\nAnonymizing user and post data:\")\n",
    "    anonymizer = Anonymizer()\n",
    "    sample_df[\"author\"] = sample_df[\"author\"].apply(anonymizer.anonymize_author)\n",
    "    sample_df[\"post_id\"] = sample_df[\"post_id\"].apply(anonymizer.anonymize_post_id)\n",
    "    sample_df[\"comment_id\"] = sample_df[\"comment_id\"].apply(\n",
    "        lambda x: anonymizer.anonymize(x, prefix=\"comment_\")\n",
    "    )\n",
    "    print(f\"Anonymized {len(sample_df):,} rows\")\n",
    "    \n",
    "    print(f\"\\nSample dataset created\")\n",
    "    print(f\"Total samples: {len(sample_df):,}\")\n",
    "    print(f\"\\nSample source distribution:\")\n",
    "    for source, count in sample_df[\"source\"].value_counts().items():\n",
    "        pct = count / len(sample_df) * 100\n",
    "        print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Save sample dataset\n",
    "    output_path = Path(\"..\") / \"data/sample_comments_2000.csv\"\n",
    "    sample_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSaved to: {output_path}\")\n",
    "    \n",
    "    # Display sample\n",
    "    print(\"\\nSample preview (anonymized):\")\n",
    "    display(sample_df.head(10))\n",
    "else:\n",
    "    print(\"No data files found. Run the fetch scripts first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Anonymizer**: Consistent hashing of usernames and IDs while preserving relationships\n",
    "2. **Filter Functions**: Blocking bots, news accounts, and non-CTA transit content\n",
    "3. **Rate Limiter**: Preventing API rate limit violations\n",
    "4. **Reddit Fetching**: Sample post retrieval with anonymization\n",
    "5. **Bluesky Configuration**: Environment variable setup for authentication\n",
    "6. **Combined Dataset**: Creating a stratified sample from multiple sources\n",
    "\n",
    "The full fetch scripts (`reddit_data_fetch.py` and `atproto_data_fetch.py`) use these utilities to collect comprehensive datasets while respecting API limits and user privacy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
